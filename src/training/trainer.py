"""
å­¦ç¿’ãƒ­ã‚¸ãƒƒã‚¯ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""
import time
import json
import os
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, asdict

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader


@dataclass
class TrainingConfig:
    """å­¦ç¿’è¨­å®š"""
    epochs: int = 5
    learning_rate: float = 0.001
    weight_decay: float = 1e-5
    scheduler_step_size: int = 3
    scheduler_gamma: float = 0.1


@dataclass
class EpochResult:
    """1ã‚¨ãƒãƒƒã‚¯ã®çµæœ"""
    epoch: int
    train_loss: float
    train_accuracy: float
    test_accuracy: float
    epoch_time: float


@dataclass
class TrainingResult:
    """å­¦ç¿’å…¨ä½“ã®çµæœ"""
    final_accuracy: float
    best_accuracy: float
    total_time: float
    epochs_completed: int
    history: List[dict]
    
    def to_dict(self) -> dict:
        return asdict(self)
    
    def save(self, path: str):
        with open(path, 'w') as f:
            json.dump(self.to_dict(), f, indent=2)


class Trainer:
    """
    ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(
        self,
        model: nn.Module,
        config: TrainingConfig,
        device: Optional[torch.device] = None
    ):
        """
        Args:
            model: å­¦ç¿’ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
            config: å­¦ç¿’è¨­å®š
            device: ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹ï¼ˆNoneã®å ´åˆã¯è‡ªå‹•æ¤œå‡ºï¼‰
        """
        self.config = config
        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = model.to(self.device)
        
        # æå¤±é–¢æ•°
        self.criterion = nn.CrossEntropyLoss()
        
        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶
        self.optimizer = optim.Adam(
            self.model.parameters(),
            lr=config.learning_rate,
            weight_decay=config.weight_decay
        )
        
        # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©
        self.scheduler = optim.lr_scheduler.StepLR(
            self.optimizer,
            step_size=config.scheduler_step_size,
            gamma=config.scheduler_gamma
        )
        
        # å±¥æ­´
        self.history: List[EpochResult] = []
    
    def train_one_epoch(self, train_loader: DataLoader) -> Tuple[float, float]:
        """
        1ã‚¨ãƒãƒƒã‚¯åˆ†ã®å­¦ç¿’ã‚’å®Ÿè¡Œ
        
        Args:
            train_loader: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
            
        Returns:
            (å¹³å‡æå¤±, æ­£è§£ç‡)
        """
        self.model.train()
        total_loss = 0.0
        correct = 0
        total = 0
        
        for images, labels in train_loader:
            images = images.to(self.device)
            labels = labels.to(self.device)
            
            # é †ä¼æ’­
            self.optimizer.zero_grad()
            outputs = self.model(images)
            loss = self.criterion(outputs, labels)
            
            # é€†ä¼æ’­
            loss.backward()
            self.optimizer.step()
            
            # çµ±è¨ˆ
            total_loss += loss.item() * images.size(0)
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
        
        avg_loss = total_loss / total
        accuracy = correct / total
        
        return avg_loss, accuracy
    
    @torch.no_grad()
    def evaluate(self, test_loader: DataLoader) -> float:
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡
        
        Args:
            test_loader: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
            
        Returns:
            æ­£è§£ç‡
        """
        self.model.eval()
        correct = 0
        total = 0
        
        for images, labels in test_loader:
            images = images.to(self.device)
            labels = labels.to(self.device)
            
            outputs = self.model(images)
            _, predicted = outputs.max(1)
            
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
        
        return correct / total
    
    def train(
        self,
        train_loader: DataLoader,
        test_loader: DataLoader,
        verbose: bool = True
    ) -> TrainingResult:
        """
        å­¦ç¿’ã‚’å®Ÿè¡Œ
        
        Args:
            train_loader: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
            test_loader: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
            verbose: é€²æ—è¡¨ç¤º
            
        Returns:
            å­¦ç¿’çµæœ
        """
        if verbose:
            print(f"ğŸ–¥ï¸  Device: {self.device}")
            print(f"ğŸ“Š Training samples: {len(train_loader.dataset)}")
            print(f"ğŸ“Š Test samples: {len(test_loader.dataset)}")
            print(f"âš™ï¸  Epochs: {self.config.epochs}")
            print(f"âš™ï¸  Learning rate: {self.config.learning_rate}")
            print("-" * 60)
        
        start_time = time.time()
        best_accuracy = 0.0
        
        for epoch in range(1, self.config.epochs + 1):
            epoch_start = time.time()
            
            # å­¦ç¿’
            train_loss, train_acc = self.train_one_epoch(train_loader)
            
            # è©•ä¾¡
            test_acc = self.evaluate(test_loader)
            
            # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©æ›´æ–°
            self.scheduler.step()
            
            # çµæœã‚’è¨˜éŒ²
            epoch_time = time.time() - epoch_start
            result = EpochResult(
                epoch=epoch,
                train_loss=round(train_loss, 4),
                train_accuracy=round(train_acc, 4),
                test_accuracy=round(test_acc, 4),
                epoch_time=round(epoch_time, 2)
            )
            self.history.append(result)
            
            # ãƒ™ã‚¹ãƒˆæ›´æ–°
            if test_acc > best_accuracy:
                best_accuracy = test_acc
            
            if verbose:
                print(
                    f"Epoch {epoch:2d}/{self.config.epochs} | "
                    f"Loss: {train_loss:.4f} | "
                    f"Train: {train_acc:.2%} | "
                    f"Test: {test_acc:.2%} | "
                    f"Time: {epoch_time:.1f}s"
                )
        
        total_time = time.time() - start_time
        
        if verbose:
            print("-" * 60)
            print(f"âœ… Training completed in {total_time:.1f}s")
            print(f"ğŸ“ˆ Best accuracy: {best_accuracy:.2%}")
        
        return TrainingResult(
            final_accuracy=round(self.history[-1].test_accuracy, 4),
            best_accuracy=round(best_accuracy, 4),
            total_time=round(total_time, 2),
            epochs_completed=self.config.epochs,
            history=[asdict(h) for h in self.history]
        )
    
    def save_model(self, path: str):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
        torch.save(self.model.state_dict(), path)
    
    def load_model(self, path: str):
        """ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        self.model.load_state_dict(torch.load(path, map_location=self.device))


def create_trainer(
    model: nn.Module,
    epochs: int = 5,
    learning_rate: float = 0.001,
    device: Optional[torch.device] = None
) -> Trainer:
    """
    Trainerã‚’ç°¡å˜ã«ä½œæˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    """
    config = TrainingConfig(
        epochs=epochs,
        learning_rate=learning_rate
    )
    return Trainer(model, config, device)
